{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1302c28",
   "metadata": {},
   "source": [
    "\n",
    "###Date of last update: 1-26-26\n",
    "This will be used\n",
    "Establish the genomic background model to correct for relatedness, to be used for testing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bda594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Hail with GRCh38\n",
    "\n",
    "import hail as hl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "hl.init(default_reference='GRCh38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Cloud Paths \n",
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "# Path to whole genome sequence data stored in hail matrix table format\n",
    "WGS_MT_PATH = \"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/splitMT/hail.mt\"\n",
    "# Path to GWAS results stored in hail table format (allele frequency and allele count)\n",
    "GWAS_RESULTS_PATH = \"gs://fc-aou-datasets-controlled/AllxAll/v1/ht/ACAF/EUR/phenotype_NS_326.1_ACAF_results.ht\"\n",
    "\n",
    "# Ancestry prediction file found here: gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter genotype data to European ancestry samples\n",
    "# 3. Process data for European ancestry samples\n",
    "print(\"Loading EUR sample IDs...\")\n",
    "!gsutil -u $GOOGLE_PROJECT cp gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/aux/ancestry/ancestry_preds.tsv ./ancestry_temp.tsv\n",
    "ancestry_df = pd.read_csv(\"./ancestry_temp.tsv\", sep=\"\\t\")\n",
    "eur_ids = set(ancestry_df[ancestry_df['ancestry_pred'] == 'eur']['research_id'].astype(str))\n",
    "!rm ./ancestry_temp.tsv\n",
    "\n",
    "\n",
    "# 4. Filter Matrix Table to EUR Samples\n",
    "wgs_mt = hl.read_matrix_table(WGS_MT_PATH)\n",
    "wgs_eur_mt = wgs_mt.filter_cols(hl.literal(eur_ids).contains(wgs_mt.s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f106c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Filter Matrix Table to ~500K Common SNPs (Crash-Proof Version)\n",
    "import random\n",
    "import hail as hl\n",
    "\n",
    "# Get reference\n",
    "rg = hl.get_reference('GRCh38')\n",
    "lengths = rg.lengths\n",
    "\n",
    "# Generate 4,000 intervals\n",
    "print(\"Generating random genomic windows...\")\n",
    "n_intervals = 4000\n",
    "window_size = 50000\n",
    "chroms = [f\"chr{i}\" for i in range(1, 23)]\n",
    "\n",
    "hl_intervals = []\n",
    "for _ in range(n_intervals):\n",
    "    chrom = random.choice(chroms)\n",
    "    chrom_len = lengths[chrom]\n",
    "    start = random.randint(1, chrom_len - window_size)\n",
    "    interval = hl.locus_interval(chrom, start, start + window_size, reference_genome='GRCh38')\n",
    "    hl_intervals.append(interval)\n",
    "\n",
    "# Convert to Table\n",
    "print(\"Converting intervals to Table...\")\n",
    "interval_structs = [{'interval': i} for i in hl_intervals]\n",
    "interval_ht = hl.Table.parallelize(\n",
    "    interval_structs, \n",
    "    schema=hl.tstruct(interval=hl.tinterval(hl.tlocus('GRCh38')))\n",
    ").key_by('interval')\n",
    "\n",
    "# Filter -> Select -> Repartition\n",
    "print(\"Filtering intervals and dropping unused fields...\")\n",
    "mt_fast_subset = wgs_eur_mt.select_entries('GT')\n",
    "mt_fast_subset = mt_fast_subset.filter_rows(hl.is_defined(interval_ht[mt_fast_subset.locus]))\n",
    "\n",
    "# CRITICAL: Repartition to 1000 to reduce overhead\n",
    "print(\"Repartitioning...\")\n",
    "mt_fast_subset = mt_fast_subset.naive_coalesce(1000) \n",
    "\n",
    "# QC\n",
    "print(\"Calculating QC...\")\n",
    "mt_fast_subset = hl.variant_qc(mt_fast_subset)\n",
    "\n",
    "# Filter for common SNPs\n",
    "common_snps_mt = mt_fast_subset.filter_rows(\n",
    "    (mt_fast_subset.variant_qc.AF[1] > 0.05) & \n",
    "    (mt_fast_subset.variant_qc.AF[1] < 0.95) &\n",
    "    (mt_fast_subset.variant_qc.call_rate > 0.95)\n",
    ")\n",
    "\n",
    "# STABILITY FIX: Write an intermediate checkpoint to DISK instead of memory\n",
    "# This breaks the lineage and prevents the driver from getting overwhelmed\n",
    "print(\"Checkpointing intermediate result to disk...\")\n",
    "checkpoint_path = f\"{bucket}/tmp/intermediate_common_snps.mt\"\n",
    "common_snps_mt = common_snps_mt.write(checkpoint_path, overwrite=True)\n",
    "common_snps_mt = hl.read_matrix_table(checkpoint_path)\n",
    "\n",
    "# Now it is safe to count because the data is fully written to disk\n",
    "n_total = common_snps_mt.count_rows()\n",
    "print(f\"Variants found: {n_total}\")\n",
    "\n",
    "# Sample\n",
    "sampling_fraction = 500000 / n_total if n_total > 500000 else 1.0\n",
    "mt_final = common_snps_mt.sample_rows(sampling_fraction, seed=42)\n",
    "\n",
    "# Final Save\n",
    "print(\"Saving final dataset...\")\n",
    "mt_final_path = f\"{bucket}/data/eur_common_snps_500k.mt\"\n",
    "mt_final.write(mt_final_path, overwrite=True)\n",
    "print(f\"Success! Final MatrixTable saved to: {mt_final_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Filter Matrix Table to Common SNPs using random 50kb windows (n=1,000) across the genome\n",
    "# import random\n",
    "# import hail as hl\n",
    "\n",
    "# # Get exact chromosome lengths for GRCh38 to avoid \"out of bounds\" errors\n",
    "# rg = hl.get_reference('GRCh38')\n",
    "# lengths = rg.lengths\n",
    "\n",
    "# # Generate 1,000 valid random 50kb intervals\n",
    "# print(\"Generating random genomic windows based on actual chromosome lengths...\")\n",
    "# n_intervals = 1000\n",
    "# window_size = 50000\n",
    "# # We only want autosomes for the Null Model (Kinship)\n",
    "# chroms = [f\"chr{i}\" for i in range(1, 23)]\n",
    "\n",
    "# hl_intervals = []\n",
    "# for _ in range(n_intervals):\n",
    "#     chrom = random.choice(chroms)\n",
    "#     chrom_len = lengths[chrom]\n",
    "#     # Ensure the window doesn't go past the end of the chromosome\n",
    "#     start = random.randint(1, chrom_len - window_size)\n",
    "#     interval = hl.locus_interval(chrom, start, start + window_size, reference_genome='GRCh38')\n",
    "#     hl_intervals.append(interval)\n",
    "\n",
    "# # Filter the genotype data to the random 50kb windows\n",
    "# # Use 30 workers on dataproc cluster $$$\n",
    "# print(\"Applying fast interval filter...\")\n",
    "# mt_fast_subset = hl.filter_intervals(wgs_eur_mt, hl_intervals)\n",
    "\n",
    "# # Perform QC and filter for Common SNPs (0.05 < MAF < 0.95 & Call Rate > 0.95)\n",
    "# print(\"Calculating QC on subset...\")\n",
    "# mt_fast_subset = hl.variant_qc(mt_fast_subset)\n",
    "# common_snps_mt = mt_fast_subset.filter_rows(\n",
    "#     (mt_fast_subset.variant_qc.AF[1] > 0.05) & \n",
    "#     (mt_fast_subset.variant_qc.AF[1] < 0.95) &\n",
    "#     (mt_fast_subset.variant_qc.call_rate > 0.95)\n",
    "# )\n",
    "\n",
    "# # 5. Checkpoint to break the lineage\n",
    "# common_snps_mt = common_snps_mt.checkpoint(f\"{bucket}/tmp/fast_common_snps_v2.mt\", overwrite=True)\n",
    "\n",
    "# # 6. Sample down to exactly 150k for Regenie\n",
    "# n_total = common_snps_mt.count_rows()\n",
    "# print(f\"Variants found: {n_total}\")\n",
    "# sampling_fraction = 150000 / n_total if n_total > 150000 else 1.0\n",
    "# mt_final = common_snps_mt.sample_rows(sampling_fraction, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66208503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
